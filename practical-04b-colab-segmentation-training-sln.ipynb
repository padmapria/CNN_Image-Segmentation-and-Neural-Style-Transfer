{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GF-f13-qJH9-"
   },
   "source": [
    "# Practical 4 Part 2 - Training Our Segmentation Model on Colab\n",
    "\n",
    "**Open this Notebook in Google's Colab (https://colab.research.google.com)**\n",
    "\n",
    "The next step is for us to train our segmentation model using the data that we've processed in Part A. \n",
    "\n",
    "In this part, we will be using the open source segmentation models created by qubvel on Github. The latest codes can be found at:\n",
    "   \n",
    "> https://github.com/qubvel/segmentation_models\n",
    "\n",
    "Running the code block below in this notebook will allow you to install the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ls_RSrtq_942"
   },
   "source": [
    "## 4.2.1 Mounting Our Google Drive\n",
    "\n",
    "First, let's mount our Google Drive containing the *.npy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28390,
     "status": "ok",
     "timestamp": 1579694386469,
     "user": {
      "displayName": "Pat LEW",
      "photoUrl": "",
      "userId": "08279461782250315515"
     },
     "user_tz": -480
    },
    "id": "3Hv_5Jk0JS-Q",
    "outputId": "8049925a-bf78-463e-b0d4-da5856345894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Run this if you are using Google Drive\n",
    "#\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXkzLXP4ADVl"
   },
   "source": [
    "## 4.2.2 Listing Files in Our Google Drive\n",
    "\n",
    "Run the following to list the files in your Data/D4 folder on Google Drive.\n",
    "\n",
    "If you haven't already uploaded your files to Google Drive, please upload the \"x\" and \"y\" folders generated from Part 1 into the Data/D4 folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3618,
     "status": "ok",
     "timestamp": 1579694397379,
     "user": {
      "displayName": "Pat LEW",
      "photoUrl": "",
      "userId": "08279461782250315515"
     },
     "user_tz": -480
    },
    "id": "GvHSfAa2JUvD",
    "outputId": "3654a2b5-4b1d-4a75-d90e-179ba8118579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  y\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/My\\ Drive/Data/D4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3J-MgHJrAcYV"
   },
   "source": [
    "## 4.2.3 Install Keras Segmentation Models\n",
    "\n",
    "Run the following cell to install the keras segmentation models in our Colab environment. \n",
    "\n",
    "*NOTE: When this Colab environment is disconnected and restarted, you may have to run this again!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9328,
     "status": "ok",
     "timestamp": 1579694411621,
     "user": {
      "displayName": "Pat LEW",
      "photoUrl": "",
      "userId": "08279461782250315515"
     },
     "user_tz": -480
    },
    "id": "3ldWx9XE2duD",
    "outputId": "ebe6b6fa-8529-44d1-d2f7-63f88aee03a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/segmentation_models\n",
      "  Cloning https://github.com/qubvel/segmentation_models to /tmp/pip-req-build-ifzne8pe\n",
      "  Running command git clone -q https://github.com/qubvel/segmentation_models /tmp/pip-req-build-ifzne8pe\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from segmentation-models==1.0.1) (1.0.8)\n",
      "Collecting image-classifiers==1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
      "Collecting efficientnet==1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.17.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (2.8.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.16.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (6.2.2)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.4.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.1.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (4.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.6.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (42.0.2)\n",
      "Building wheels for collected packages: segmentation-models\n",
      "  Building wheel for segmentation-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for segmentation-models: filename=segmentation_models-1.0.1-cp36-none-any.whl size=33587 sha256=a8d4c788203fe4b089aace2741eee508aefeafabd0d177e4ca954d662fbb7863\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-41y36cxu/wheels/49/cf/46/cbb4bb64518c402aea99df9d466f1081450597e653256bbcf4\n",
      "Successfully built segmentation-models\n",
      "Installing collected packages: image-classifiers, efficientnet, segmentation-models\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/qubvel/segmentation_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_j-6Bk6C_8BZ"
   },
   "source": [
    "## 4.2.4 Import All Necessary Libraries\n",
    "\n",
    "Run the following cell to import all necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3102,
     "status": "ok",
     "timestamp": 1579694432243,
     "user": {
      "displayName": "Pat LEW",
      "photoUrl": "",
      "userId": "08279461782250315515"
     },
     "user_tz": -480
    },
    "id": "5OyH7PS3sFVO",
    "outputId": "52447076-e577-4351-a982-2b28fb3f35a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import segmentation_models as sm\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from segmentation_models.utils import set_trainable\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1e-kqlpoAExa"
   },
   "source": [
    "## 4.2.5 Declaring Our Data Batch Generator\n",
    "\n",
    "Run the following cell to declare our Data Generator class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lM1_VP3xqyOb"
   },
   "outputs": [],
   "source": [
    "# The DataGenerator class is a Sequence class used by Keras\n",
    "# to load data in batches during training\n",
    "# \n",
    "# See https://keras.io/utils/ for more info.\n",
    "#\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, x_path, y_path, file_IDs, samples_per_file, batch_size, process_x=None, process_y=None, load_to_memory=True):\n",
    "        # Initialization\n",
    "        self.samples_per_file = samples_per_file\n",
    "        self.batch_size = batch_size\n",
    "        self.perm_batch_size = batch_size\n",
    "\n",
    "        self.load_to_memory = False\n",
    "        self.x_path = x_path\n",
    "        self.y_path = y_path        \n",
    "        self.file_IDs = file_IDs\n",
    "\n",
    "        self.current_loaded_file_ID = -1\n",
    "        self.current_loaded_x = None\n",
    "        self.current_loaded_y = None\n",
    "        \n",
    "        self.all_x = {}\n",
    "        self.all_y = {}\n",
    "        \n",
    "        self.process_x = process_x\n",
    "        self.process_y = process_y\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        # Check for the presence of the files,\n",
    "        # and remove those batch IDs that doesn't exist.\n",
    "        #\n",
    "        self.file_IDs = []\n",
    "        \n",
    "        \n",
    "        for i in range(0, len(file_IDs)):\n",
    "            ID = file_IDs[i]\n",
    "            if os.path.exists(self.x_path + (\"/%d\" % ID) + '.npy') and os.path.exists(self.y_path + (\"/%d\" % ID) + '.npy'):\n",
    "                self.file_IDs.append(file_IDs[i])\n",
    "            else:\n",
    "                print (\"File path: %s or %s not found\" % (self.x_path + (\"/%d\" % ID) + '.npy', self.y_path + (\"/%d\" % ID) + '.npy'))\n",
    "        print (self.file_IDs)\n",
    "        print (\"Total of %d files\" % (len(self.file_IDs)))\n",
    "\n",
    "        if (load_to_memory):\n",
    "            for i, ID in enumerate(self.file_IDs):\n",
    "                # Load input and output all into memory\n",
    "                # This should only be used if your computer's memory \n",
    "                # is sufficient to hold all the data from training.\n",
    "                # \n",
    "                self.all_x[ID], self.all_y[ID] = self.load_file(ID)\n",
    "\n",
    "                if (i % 10 == 0):\n",
    "                    print (\"Loading file into memory (%d out of %d)\" % (i, len(self.file_IDs)))\n",
    "\n",
    "            self.load_to_memory = True\n",
    "\n",
    "            print (\"Loading files into memory complete.\")\n",
    "\n",
    "    # Returns the number of batches per epoch\n",
    "    #\n",
    "    def __len__(self):\n",
    "        return int(len(self.file_IDs) * self.samples_per_file / self.batch_size)\n",
    "\n",
    "\n",
    "    # Generates data containing batch_size samples.\n",
    "    # This is called by Keras during training to retrieve\n",
    "    # the set of data for each batch.\n",
    "    #    \n",
    "    def __getitem__(self, index):\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        sample_number = index * self.batch_size\n",
    "\n",
    "        which_file = int(sample_number / self.samples_per_file)\n",
    "        which_position_in_file = sample_number % self.samples_per_file\n",
    "\n",
    "        #print (\"  index: %d file: %d pos: %d\" % (index, which_file, which_position_in_file))\n",
    "\n",
    "        ID = self.file_IDs[which_file]\n",
    "        fx, fy = self.load_file(ID)\n",
    "\n",
    "        # Load data\n",
    "        for i in range(0, self.batch_size):\n",
    "            \n",
    "            if which_position_in_file < len(fx) and which_position_in_file < len(fy):\n",
    "                x.append(fx[which_position_in_file])\n",
    "                y.append(fy[which_position_in_file])\n",
    "\n",
    "            which_position_in_file = which_position_in_file + 1\n",
    "\n",
    "            if which_position_in_file >= self.samples_per_file and i != self.batch_size - 1:\n",
    "                which_position_in_file = 0\n",
    "                which_file = which_file + 1\n",
    "\n",
    "                if which_file >= len(self.file_IDs):\n",
    "                    break\n",
    "\n",
    "                ID = self.file_IDs[which_file]\n",
    "                fx, fy = self.load_file(ID)\n",
    "\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        # perform any additional processing, if the function\n",
    "        # is provided.\n",
    "        #\n",
    "        if (not self.process_x is None):\n",
    "            x = self.process_x(x)\n",
    "        if (not self.process_y is None):\n",
    "            y = self.process_y(y)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    # Resets indexes after each epoch\n",
    "    #\n",
    "    def on_epoch_end(self):\n",
    "        self.batch_size = self.perm_batch_size\n",
    "        self.current_loaded_file_ID = -1\n",
    "\n",
    "    # Load file\n",
    "    #\n",
    "    def load_file(self, ID):\n",
    "        if ID != self.current_loaded_file_ID:\n",
    "            #print (\"getting file ID %d...\" % (ID))\n",
    "\n",
    "            if (self.load_to_memory):\n",
    "                x = self.all_x[ID]\n",
    "                y = self.all_y[ID]\n",
    "            else:\n",
    "                x = np.load(self.x_path + (\"/%d\" % ID) + '.npy')\n",
    "                y = np.load(self.y_path + (\"/%d\" % ID) + '.npy')\n",
    "\n",
    "            self.current_loaded_file_ID = ID;\n",
    "            self.current_loaded_x = x\n",
    "            self.current_loaded_y = y\n",
    "\n",
    "        else:\n",
    "            x = self.current_loaded_x\n",
    "            y = self.current_loaded_y\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def set_batch_size_to_1(self):\n",
    "        self.batch_size = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLBWfxdrAnx1"
   },
   "source": [
    "## 4.2.6 Load the Processed X and Y Training Data\n",
    "\n",
    "Copy the following code to the TODO section below to load our data from the folders. We will use file numbers 0 to 15 for the training, and 16 to 19 for the validation. Each file contains 50 samples for training, and we are using 8 samples per batch.\n",
    "\n",
    "```\n",
    "train_data = DataGenerator(x_folder, y_folder, range(0, 16), 50, 8, preprocess_input, None, True)\n",
    "test_data = DataGenerator(x_folder, y_folder, range(16, 20), 50, 8, preprocess_input, None, True)\n",
    "```\n",
    "\n",
    "Then, run the following cell to initialize some variables, and load the X and Y training data from our Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16039,
     "status": "ok",
     "timestamp": 1579695125556,
     "user": {
      "displayName": "Pat LEW",
      "photoUrl": "",
      "userId": "08279461782250315515"
     },
     "user_tz": -480
    },
    "id": "NQWcOiqXJH-G",
    "outputId": "506852de-bb9e-49d9-e6c7-bcee94101ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path: /content/drive/My Drive/Data/D4/x/5.npy or /content/drive/My Drive/Data/D4/y/5.npy not found\n",
      "File path: /content/drive/My Drive/Data/D4/x/6.npy or /content/drive/My Drive/Data/D4/y/6.npy not found\n",
      "File path: /content/drive/My Drive/Data/D4/x/7.npy or /content/drive/My Drive/Data/D4/y/7.npy not found\n",
      "File path: /content/drive/My Drive/Data/D4/x/8.npy or /content/drive/My Drive/Data/D4/y/8.npy not found\n",
      "File path: /content/drive/My Drive/Data/D4/x/9.npy or /content/drive/My Drive/Data/D4/y/9.npy not found\n",
      "[0, 1, 2, 3, 4, 10, 11, 12, 13, 14, 15]\n",
      "Total of 11 files\n",
      "Loading file into memory (0 out of 11)\n",
      "Loading file into memory (10 out of 11)\n",
      "Loading files into memory complete.\n",
      "[16, 17, 18, 19]\n",
      "Total of 4 files\n",
      "Loading file into memory (0 out of 4)\n",
      "Loading files into memory complete.\n"
     ]
    }
   ],
   "source": [
    "# Set this to the folder containing your files\n",
    "#\n",
    "npy_folder = '/content/drive/My Drive/Data/D4/'\n",
    "x_folder = npy_folder + \"x\"\n",
    "y_folder = npy_folder + \"y\"\n",
    "\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "# Total number of classes we will predict.\n",
    "#\n",
    "num_classes = 4\n",
    "\n",
    "# Choose the backbone for our segmentation model\n",
    "#\n",
    "#   resnet18 / resnet34 / resnet50 / resnet101 / resnext50, resnext101, mobilenet, inceptionv2, inceptionv3\n",
    "#\n",
    "# You may have to adjust the input+output dimensions for different backbones.\n",
    "#\n",
    "backbone = 'resnet34'   \n",
    "\n",
    "# Get the preprocessor\n",
    "preprocess_input = sm.get_preprocessing(backbone)\n",
    "\n",
    "# Choose the segmentation network\n",
    "# unet / linknet / pspnet / fpn\n",
    "#\n",
    "network = 'unet'   \n",
    "\n",
    "# Training parameters\n",
    "#\n",
    "freeze_encoder_epochs = 50\n",
    "#unfreeze_encoder_epochs = 100\n",
    "\n",
    "# TODO:\n",
    "# Load the training and test data into our batch generator\n",
    "# NOTE: If you see the allow_pickle error when using Google Drive, just ignore \n",
    "#       it, and wait for a few minutes or re-upload the files again. \n",
    "#\n",
    "#...#\n",
    "train_data = DataGenerator(x_folder, y_folder, range(0, 16), 50, 8, preprocess_input, None, True)\n",
    "test_data = DataGenerator(x_folder, y_folder, range(16, 20), 50, 8, preprocess_input, None, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Mm1oZhLBkVn"
   },
   "source": [
    "## 4.2.7 Perform the Training\n",
    "\n",
    "Depending on the model and backbone that you select, training may take 10-20 minutes. \n",
    "\n",
    "As the model trains, keep a lookout for the scoring metrics that we have added. Unlike in the normal classification training where use accuracy, in this case we make use of the Intersection-over-Union as the scoring metric to determine how well our model performs. With this set of data and this model configuration, we are likely to see around 60-65% average IoU scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 400408,
     "status": "ok",
     "timestamp": 1579695555805,
     "user": {
      "displayName": "Pat LEW",
      "photoUrl": "",
      "userId": "08279461782250315515"
     },
     "user_tz": -480
    },
    "id": "-17G-ZcFRb9S",
    "outputId": "c2b7b03b-181d-44f8-bfb7-e893cf62840c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5\n",
      "85524480/85521592 [==============================] - 3s 0us/step\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 288, 192, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 288, 192, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 294, 198, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 144, 96, 64)  9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 144, 96, 64)  256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 144, 96, 64)  0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 146, 98, 64)  0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 72, 48, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 72, 48, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 72, 48, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 74, 50, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 72, 48, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 72, 48, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 72, 48, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 74, 50, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 72, 48, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 72, 48, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 72, 48, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 72, 48, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 72, 48, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 74, 50, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 72, 48, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 72, 48, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 72, 48, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 74, 50, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 72, 48, 64)   36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 72, 48, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 72, 48, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 72, 48, 64)   0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 74, 50, 64)   0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 72, 48, 64)   36864       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 72, 48, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 72, 48, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 74, 50, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 72, 48, 64)   36864       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 72, 48, 64)   0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 72, 48, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 72, 48, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 74, 50, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 36, 24, 128)  73728       zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 36, 24, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 36, 24, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 38, 26, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 36, 24, 128)  147456      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 36, 24, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 36, 24, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 36, 24, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 36, 24, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 38, 26, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 36, 24, 128)  147456      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 36, 24, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 36, 24, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 38, 26, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 36, 24, 128)  147456      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 36, 24, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 36, 24, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 36, 24, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 38, 26, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 36, 24, 128)  147456      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 36, 24, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 36, 24, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 38, 26, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 36, 24, 128)  147456      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 36, 24, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 36, 24, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 36, 24, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 38, 26, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 36, 24, 128)  147456      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 36, 24, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 36, 24, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 38, 26, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 36, 24, 128)  147456      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 36, 24, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 36, 24, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 36, 24, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 38, 26, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 18, 12, 256)  294912      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 18, 12, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 18, 12, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 18, 12, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 18, 12, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 18, 12, 256)  1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 18, 12, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 18, 12, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 18, 12, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 18, 12, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 18, 12, 256)  1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 18, 12, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 18, 12, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 18, 12, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 18, 12, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 18, 12, 256)  1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 18, 12, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 18, 12, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 18, 12, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 18, 12, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 18, 12, 256)  1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 18, 12, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 18, 12, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 18, 12, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 18, 12, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 18, 12, 256)  1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 18, 12, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 18, 12, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 18, 12, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, 20, 14, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 18, 12, 256)  589824      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 18, 12, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 18, 12, 256)  1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 18, 12, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, 20, 14, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 9, 6, 512)    1179648     zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 9, 6, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 9, 6, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, 11, 8, 512)   0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 9, 6, 512)    2359296     zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 9, 6, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 9, 6, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 9, 6, 512)    2048        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 9, 6, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, 11, 8, 512)   0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 9, 6, 512)    2359296     zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 9, 6, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 9, 6, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 11, 8, 512)   0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 9, 6, 512)    2359296     zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 9, 6, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 9, 6, 512)    2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 9, 6, 512)    0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 11, 8, 512)   0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 9, 6, 512)    2359296     zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 9, 6, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 9, 6, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, 11, 8, 512)   0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 9, 6, 512)    2359296     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 9, 6, 512)    0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 9, 6, 512)    2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 9, 6, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsampling (UpSa (None, 18, 12, 512)  0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_concat (Concaten (None, 18, 12, 768)  0           decoder_stage0_upsampling[0][0]  \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_conv (Conv2D)   (None, 18, 12, 256)  1769472     decoder_stage0_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_bn (BatchNormal (None, 18, 12, 256)  1024        decoder_stage0a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0a_relu (Activatio (None, 18, 12, 256)  0           decoder_stage0a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_conv (Conv2D)   (None, 18, 12, 256)  589824      decoder_stage0a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_bn (BatchNormal (None, 18, 12, 256)  1024        decoder_stage0b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0b_relu (Activatio (None, 18, 12, 256)  0           decoder_stage0b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsampling (UpSa (None, 36, 24, 256)  0           decoder_stage0b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_concat (Concaten (None, 36, 24, 384)  0           decoder_stage1_upsampling[0][0]  \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_conv (Conv2D)   (None, 36, 24, 128)  442368      decoder_stage1_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_bn (BatchNormal (None, 36, 24, 128)  512         decoder_stage1a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1a_relu (Activatio (None, 36, 24, 128)  0           decoder_stage1a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_conv (Conv2D)   (None, 36, 24, 128)  147456      decoder_stage1a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_bn (BatchNormal (None, 36, 24, 128)  512         decoder_stage1b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1b_relu (Activatio (None, 36, 24, 128)  0           decoder_stage1b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsampling (UpSa (None, 72, 48, 128)  0           decoder_stage1b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_concat (Concaten (None, 72, 48, 192)  0           decoder_stage2_upsampling[0][0]  \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_conv (Conv2D)   (None, 72, 48, 64)   110592      decoder_stage2_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_bn (BatchNormal (None, 72, 48, 64)   256         decoder_stage2a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2a_relu (Activatio (None, 72, 48, 64)   0           decoder_stage2a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_conv (Conv2D)   (None, 72, 48, 64)   36864       decoder_stage2a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_bn (BatchNormal (None, 72, 48, 64)   256         decoder_stage2b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2b_relu (Activatio (None, 72, 48, 64)   0           decoder_stage2b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsampling (UpSa (None, 144, 96, 64)  0           decoder_stage2b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_concat (Concaten (None, 144, 96, 128) 0           decoder_stage3_upsampling[0][0]  \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_conv (Conv2D)   (None, 144, 96, 32)  36864       decoder_stage3_concat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_bn (BatchNormal (None, 144, 96, 32)  128         decoder_stage3a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3a_relu (Activatio (None, 144, 96, 32)  0           decoder_stage3a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_conv (Conv2D)   (None, 144, 96, 32)  9216        decoder_stage3a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_bn (BatchNormal (None, 144, 96, 32)  128         decoder_stage3b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3b_relu (Activatio (None, 144, 96, 32)  0           decoder_stage3b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsampling (UpSa (None, 288, 192, 32) 0           decoder_stage3b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_conv (Conv2D)   (None, 288, 192, 16) 4608        decoder_stage4_upsampling[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_bn (BatchNormal (None, 288, 192, 16) 64          decoder_stage4a_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4a_relu (Activatio (None, 288, 192, 16) 0           decoder_stage4a_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_conv (Conv2D)   (None, 288, 192, 16) 2304        decoder_stage4a_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_bn (BatchNormal (None, 288, 192, 16) 64          decoder_stage4b_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4b_relu (Activatio (None, 288, 192, 16) 0           decoder_stage4b_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, 288, 192, 4)  580         decoder_stage4b_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 288, 192, 4)  0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,456,589\n",
      "Trainable params: 3,167,495\n",
      "Non-trainable params: 21,289,094\n",
      "__________________________________________________________________________________________________\n",
      "Freeze encoder training...\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.6606 - iou_score: 0.3624 - acc: 0.8227Epoch 1/50\n",
      "68/68 [==============================] - 32s 476ms/step - loss: 0.6585 - iou_score: 0.3645 - acc: 0.8241 - val_loss: 0.9992 - val_iou_score: 0.2603 - val_acc: 0.6345\n",
      "Epoch 2/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.4584 - iou_score: 0.5642 - acc: 0.9190Epoch 1/50\n",
      "68/68 [==============================] - 8s 114ms/step - loss: 0.4575 - iou_score: 0.5649 - acc: 0.9191 - val_loss: 0.7213 - val_iou_score: 0.3987 - val_acc: 0.8238\n",
      "Epoch 3/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.3787 - iou_score: 0.6410 - acc: 0.9365Epoch 1/50\n",
      "68/68 [==============================] - 8s 115ms/step - loss: 0.3800 - iou_score: 0.6398 - acc: 0.9364 - val_loss: 0.5059 - val_iou_score: 0.5286 - val_acc: 0.9180\n",
      "Epoch 4/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.3351 - iou_score: 0.6831 - acc: 0.9455Epoch 1/50\n",
      "68/68 [==============================] - 8s 115ms/step - loss: 0.3330 - iou_score: 0.6851 - acc: 0.9458 - val_loss: 0.4898 - val_iou_score: 0.5501 - val_acc: 0.9174\n",
      "Epoch 5/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.3019 - iou_score: 0.7151 - acc: 0.9516Epoch 1/50\n",
      "68/68 [==============================] - 8s 116ms/step - loss: 0.3017 - iou_score: 0.7153 - acc: 0.9516 - val_loss: 0.4477 - val_iou_score: 0.5772 - val_acc: 0.9286\n",
      "Epoch 6/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.2706 - iou_score: 0.7446 - acc: 0.9568Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.2735 - iou_score: 0.7419 - acc: 0.9563 - val_loss: 0.4649 - val_iou_score: 0.5621 - val_acc: 0.9316\n",
      "Epoch 7/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.2544 - iou_score: 0.7603 - acc: 0.9596Epoch 1/50\n",
      "68/68 [==============================] - 7s 104ms/step - loss: 0.2570 - iou_score: 0.7579 - acc: 0.9595 - val_loss: 0.4576 - val_iou_score: 0.5752 - val_acc: 0.9275\n",
      "Epoch 8/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.2444 - iou_score: 0.7699 - acc: 0.9619Epoch 1/50\n",
      "68/68 [==============================] - 8s 114ms/step - loss: 0.2433 - iou_score: 0.7710 - acc: 0.9620 - val_loss: 0.4411 - val_iou_score: 0.5877 - val_acc: 0.9339\n",
      "Epoch 9/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.2345 - iou_score: 0.7797 - acc: 0.9629Epoch 1/50\n",
      "68/68 [==============================] - 8s 114ms/step - loss: 0.2356 - iou_score: 0.7786 - acc: 0.9628 - val_loss: 0.4376 - val_iou_score: 0.5877 - val_acc: 0.9368\n",
      "Epoch 10/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.2135 - iou_score: 0.7994 - acc: 0.9666Epoch 1/50\n",
      "68/68 [==============================] - 7s 106ms/step - loss: 0.2148 - iou_score: 0.7981 - acc: 0.9665 - val_loss: 0.4765 - val_iou_score: 0.5540 - val_acc: 0.9339\n",
      "Epoch 11/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.2105 - iou_score: 0.8023 - acc: 0.9669Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.2141 - iou_score: 0.7990 - acc: 0.9666 - val_loss: 0.4626 - val_iou_score: 0.5662 - val_acc: 0.9346\n",
      "Epoch 12/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.2028 - iou_score: 0.8096 - acc: 0.9689Epoch 1/50\n",
      "68/68 [==============================] - 8s 113ms/step - loss: 0.2040 - iou_score: 0.8084 - acc: 0.9689 - val_loss: 0.4251 - val_iou_score: 0.6033 - val_acc: 0.9378\n",
      "Epoch 13/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1850 - iou_score: 0.8265 - acc: 0.9712Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1861 - iou_score: 0.8254 - acc: 0.9712 - val_loss: 0.4339 - val_iou_score: 0.5919 - val_acc: 0.9375\n",
      "Epoch 14/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1808 - iou_score: 0.8303 - acc: 0.9720Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1800 - iou_score: 0.8310 - acc: 0.9720 - val_loss: 0.4347 - val_iou_score: 0.5935 - val_acc: 0.9375\n",
      "Epoch 15/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1730 - iou_score: 0.8377 - acc: 0.9731Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1730 - iou_score: 0.8376 - acc: 0.9732 - val_loss: 0.4496 - val_iou_score: 0.5805 - val_acc: 0.9374\n",
      "Epoch 16/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1732 - iou_score: 0.8376 - acc: 0.9734Epoch 1/50\n",
      "68/68 [==============================] - 8s 113ms/step - loss: 0.1724 - iou_score: 0.8384 - acc: 0.9734 - val_loss: 0.4228 - val_iou_score: 0.6028 - val_acc: 0.9399\n",
      "Epoch 17/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1618 - iou_score: 0.8481 - acc: 0.9751Epoch 1/50\n",
      "68/68 [==============================] - 8s 114ms/step - loss: 0.1613 - iou_score: 0.8486 - acc: 0.9751 - val_loss: 0.4081 - val_iou_score: 0.6178 - val_acc: 0.9423\n",
      "Epoch 18/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1544 - iou_score: 0.8551 - acc: 0.9763Epoch 1/50\n",
      "68/68 [==============================] - 7s 104ms/step - loss: 0.1530 - iou_score: 0.8565 - acc: 0.9765 - val_loss: 0.4224 - val_iou_score: 0.6109 - val_acc: 0.9381\n",
      "Epoch 19/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1611 - iou_score: 0.8488 - acc: 0.9753Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1600 - iou_score: 0.8499 - acc: 0.9754 - val_loss: 0.4424 - val_iou_score: 0.5932 - val_acc: 0.9353\n",
      "Epoch 20/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1517 - iou_score: 0.8576 - acc: 0.9764Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1559 - iou_score: 0.8538 - acc: 0.9759 - val_loss: 0.4501 - val_iou_score: 0.5832 - val_acc: 0.9333\n",
      "Epoch 21/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1763 - iou_score: 0.8345 - acc: 0.9733Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1748 - iou_score: 0.8359 - acc: 0.9735 - val_loss: 0.4577 - val_iou_score: 0.5849 - val_acc: 0.9306\n",
      "Epoch 22/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1665 - iou_score: 0.8436 - acc: 0.9752Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1654 - iou_score: 0.8446 - acc: 0.9753 - val_loss: 0.4371 - val_iou_score: 0.6001 - val_acc: 0.9326\n",
      "Epoch 23/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1488 - iou_score: 0.8604 - acc: 0.9775Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1484 - iou_score: 0.8608 - acc: 0.9775 - val_loss: 0.4286 - val_iou_score: 0.6035 - val_acc: 0.9351\n",
      "Epoch 24/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1302 - iou_score: 0.8780 - acc: 0.9795Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1328 - iou_score: 0.8754 - acc: 0.9796 - val_loss: 0.4117 - val_iou_score: 0.6153 - val_acc: 0.9412\n",
      "Epoch 25/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1326 - iou_score: 0.8755 - acc: 0.9803Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1322 - iou_score: 0.8758 - acc: 0.9804 - val_loss: 0.4402 - val_iou_score: 0.5916 - val_acc: 0.9357\n",
      "Epoch 26/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1343 - iou_score: 0.8740 - acc: 0.9798Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1338 - iou_score: 0.8744 - acc: 0.9799 - val_loss: 0.4429 - val_iou_score: 0.5893 - val_acc: 0.9379\n",
      "Epoch 27/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1518 - iou_score: 0.8575 - acc: 0.9776Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1514 - iou_score: 0.8579 - acc: 0.9776 - val_loss: 0.4355 - val_iou_score: 0.5964 - val_acc: 0.9362\n",
      "Epoch 28/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1324 - iou_score: 0.8759 - acc: 0.9796Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1318 - iou_score: 0.8764 - acc: 0.9797 - val_loss: 0.4306 - val_iou_score: 0.6022 - val_acc: 0.9389\n",
      "Epoch 29/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1203 - iou_score: 0.8871 - acc: 0.9816Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.1216 - iou_score: 0.8860 - acc: 0.9815 - val_loss: 0.4121 - val_iou_score: 0.6191 - val_acc: 0.9416\n",
      "Epoch 30/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1153 - iou_score: 0.8920 - acc: 0.9823Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1149 - iou_score: 0.8924 - acc: 0.9824 - val_loss: 0.4198 - val_iou_score: 0.6110 - val_acc: 0.9404\n",
      "Epoch 31/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1146 - iou_score: 0.8925 - acc: 0.9828Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1139 - iou_score: 0.8931 - acc: 0.9828 - val_loss: 0.4110 - val_iou_score: 0.6180 - val_acc: 0.9416\n",
      "Epoch 32/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1089 - iou_score: 0.8979 - acc: 0.9833Epoch 1/50\n",
      "68/68 [==============================] - 8s 113ms/step - loss: 0.1083 - iou_score: 0.8985 - acc: 0.9834 - val_loss: 0.4070 - val_iou_score: 0.6227 - val_acc: 0.9426\n",
      "Epoch 33/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1052 - iou_score: 0.9014 - acc: 0.9841Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1046 - iou_score: 0.9020 - acc: 0.9842 - val_loss: 0.4117 - val_iou_score: 0.6185 - val_acc: 0.9439\n",
      "Epoch 34/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.1063 - iou_score: 0.9002 - acc: 0.9842Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.1077 - iou_score: 0.8989 - acc: 0.9839 - val_loss: 0.4074 - val_iou_score: 0.6225 - val_acc: 0.9443\n",
      "Epoch 35/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0990 - iou_score: 0.9072 - acc: 0.9851Epoch 1/50\n",
      "68/68 [==============================] - 8s 113ms/step - loss: 0.0984 - iou_score: 0.9078 - acc: 0.9852 - val_loss: 0.3993 - val_iou_score: 0.6297 - val_acc: 0.9442\n",
      "Epoch 36/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0927 - iou_score: 0.9133 - acc: 0.9860Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0923 - iou_score: 0.9137 - acc: 0.9860 - val_loss: 0.4081 - val_iou_score: 0.6216 - val_acc: 0.9438\n",
      "Epoch 37/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0887 - iou_score: 0.9170 - acc: 0.9865Epoch 1/50\n",
      "68/68 [==============================] - 7s 104ms/step - loss: 0.0881 - iou_score: 0.9177 - acc: 0.9866 - val_loss: 0.4111 - val_iou_score: 0.6206 - val_acc: 0.9431\n",
      "Epoch 38/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0846 - iou_score: 0.9208 - acc: 0.9873Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0843 - iou_score: 0.9211 - acc: 0.9873 - val_loss: 0.4052 - val_iou_score: 0.6251 - val_acc: 0.9442\n",
      "Epoch 39/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0819 - iou_score: 0.9234 - acc: 0.9877Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.0816 - iou_score: 0.9237 - acc: 0.9877 - val_loss: 0.4087 - val_iou_score: 0.6216 - val_acc: 0.9439\n",
      "Epoch 40/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0793 - iou_score: 0.9258 - acc: 0.9882Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0794 - iou_score: 0.9257 - acc: 0.9881 - val_loss: 0.4125 - val_iou_score: 0.6186 - val_acc: 0.9434\n",
      "Epoch 41/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0785 - iou_score: 0.9265 - acc: 0.9883Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0779 - iou_score: 0.9271 - acc: 0.9884 - val_loss: 0.4223 - val_iou_score: 0.6110 - val_acc: 0.9424\n",
      "Epoch 42/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0848 - iou_score: 0.9206 - acc: 0.9874Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0842 - iou_score: 0.9211 - acc: 0.9874 - val_loss: 0.4183 - val_iou_score: 0.6178 - val_acc: 0.9425\n",
      "Epoch 43/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0803 - iou_score: 0.9249 - acc: 0.9880Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0803 - iou_score: 0.9249 - acc: 0.9880 - val_loss: 0.4154 - val_iou_score: 0.6182 - val_acc: 0.9432\n",
      "Epoch 44/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0773 - iou_score: 0.9276 - acc: 0.9885Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0769 - iou_score: 0.9279 - acc: 0.9885 - val_loss: 0.4211 - val_iou_score: 0.6137 - val_acc: 0.9418\n",
      "Epoch 45/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0794 - iou_score: 0.9256 - acc: 0.9881Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0793 - iou_score: 0.9257 - acc: 0.9880 - val_loss: 0.4033 - val_iou_score: 0.6283 - val_acc: 0.9452\n",
      "Epoch 46/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0754 - iou_score: 0.9293 - acc: 0.9888Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0756 - iou_score: 0.9292 - acc: 0.9887 - val_loss: 0.4250 - val_iou_score: 0.6103 - val_acc: 0.9415\n",
      "Epoch 47/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0759 - iou_score: 0.9289 - acc: 0.9885Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0757 - iou_score: 0.9291 - acc: 0.9885 - val_loss: 0.4231 - val_iou_score: 0.6153 - val_acc: 0.9412\n",
      "Epoch 48/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0838 - iou_score: 0.9214 - acc: 0.9870Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.0842 - iou_score: 0.9211 - acc: 0.9869 - val_loss: 0.4175 - val_iou_score: 0.6150 - val_acc: 0.9425\n",
      "Epoch 49/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0780 - iou_score: 0.9269 - acc: 0.9882Epoch 1/50\n",
      "68/68 [==============================] - 7s 103ms/step - loss: 0.0777 - iou_score: 0.9273 - acc: 0.9882 - val_loss: 0.4133 - val_iou_score: 0.6204 - val_acc: 0.9423\n",
      "Epoch 50/50\n",
      "67/68 [============================>.] - ETA: 0s - loss: 0.0863 - iou_score: 0.9190 - acc: 0.9873Epoch 1/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 0.0863 - iou_score: 0.9190 - acc: 0.9872 - val_loss: 0.4230 - val_iou_score: 0.6154 - val_acc: 0.9402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# OPTIONAL:\\n# This section unfreezes the layers in the backbone model and continues on with the training.\\n\\n# release all layers for training\\nfor layer in model.layers:\\n    layer.trainable = True\\n\\n\\n# Compile the model again\\n#\\nmodel.compile(\\n    \\'Adam\\',\\n    loss=sm.losses.categorical_focal_jaccard_loss,\\n    metrics=[sm.metrics.iou_score, \\'accuracy\\'],\\n)\\n\\n# Configure the checkpoint and stop point.\\n# This allows the training to save the best models and also stop the\\n# training early if it detects that there are no improvements after\\n# a long time.\\n#\\ncallbacks_list = [\\n    keras.callbacks.ModelCheckpoint(\\n        filepath=training_session_folder + \\'/seg_\\' + \\n            network + \\'_\\' + \\n            backbone + \\'_\\' + \\n            \\'model.b.{epoch:04d}-acc-{acc:4.2f}-val_acc-{val_acc:4.2f}-{val_iou_score:.2f}-loss-{val_loss:4.2f}.h5\\',\\n        monitor=\\'val_loss\\', save_best_only=True),\\n    keras.callbacks.EarlyStopping(monitor=\\'val_loss\\', patience=30)\\n]\\n\\n\\n# Train model again\\n#\\nprint (\"Unfreeze encoder training...\")\\nhistory2 = model.fit_generator(train_data, epochs=unfreeze_encoder_epochs, verbose=True, validation_data=test_data, callbacks=callbacks_list)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the training folder\n",
    "#\n",
    "training_session_id = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "training_session_folder = npy_folder + '/segmentation_train_%s' % (training_session_id)\n",
    "os.makedirs(training_session_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# TODO: \n",
    "# Define segmentation model\n",
    "#\n",
    "# This code creates the corresponding segmentation network based on the variable declared in the \"network\" variable.\n",
    "# define model\n",
    "#\n",
    "if network == 'unet':\n",
    "    # Input width/height must be divisible by 32.\n",
    "    model = sm.Unet(backbone, input_shape=(288, 192, 3), encoder_weights='imagenet', encoder_freeze=True, classes=num_classes, activation='softmax')\n",
    "if network == 'fpn':\n",
    "    # Input width/height must be divisible by 32.\n",
    "    model = sm.FPN(backbone, input_shape=(288, 192, 3), encoder_weights='imagenet', encoder_freeze=True, classes=num_classes, activation='softmax')\n",
    "if network == 'pspnet':\n",
    "    # Input width/height must be divisible by 48.\n",
    "    model = sm.PSPNet(backbone, input_shape=(288, 192, 3), encoder_weights='imagenet', encoder_freeze=True, classes=num_classes, activation='softmax')\n",
    "if network == 'linknet':\n",
    "    # Input width/height must be divisible by 32.\n",
    "    model = sm.Linknet(backbone, input_shape=(288, 192, 3), encoder_weights='imagenet', encoder_freeze=True, classes=num_classes, activation='softmax')\n",
    "\n",
    "# Compile model\n",
    "#\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss=sm.losses.categorical_focal_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score, 'accuracy'],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Configure the checkpoint and stop point.\n",
    "# This allows the training to save the best models and also stop the\n",
    "# training early if it detects that there are no improvements after\n",
    "# a long time.\n",
    "#\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=training_session_folder + '/seg_' + \n",
    "            network + '_' + \n",
    "            backbone + '_' + \n",
    "            'model.a.{epoch:04d}-acc-{acc:4.2f}-val_acc-{val_acc:4.2f}-{val_iou_score:.2f}-loss-{val_loss:4.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "]\n",
    "\n",
    "\n",
    "# pre-train the decoder weights\n",
    "#\n",
    "print (\"Freeze encoder training...\")\n",
    "history1 = model.fit_generator(train_data, epochs=freeze_encoder_epochs, verbose=True, validation_data=test_data, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "'''\n",
    "# OPTIONAL:\n",
    "# This section unfreezes the layers in the backbone model and continues on with the training.\n",
    "\n",
    "# release all layers for training\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "# Compile the model again\n",
    "#\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    loss=sm.losses.categorical_focal_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score, 'accuracy'],\n",
    ")\n",
    "\n",
    "# Configure the checkpoint and stop point.\n",
    "# This allows the training to save the best models and also stop the\n",
    "# training early if it detects that there are no improvements after\n",
    "# a long time.\n",
    "#\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=training_session_folder + '/seg_' + \n",
    "            network + '_' + \n",
    "            backbone + '_' + \n",
    "            'model.b.{epoch:04d}-acc-{acc:4.2f}-val_acc-{val_acc:4.2f}-{val_iou_score:.2f}-loss-{val_loss:4.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "]\n",
    "\n",
    "\n",
    "# Train model again\n",
    "#\n",
    "print (\"Unfreeze encoder training...\")\n",
    "history2 = model.fit_generator(train_data, epochs=unfreeze_encoder_epochs, verbose=True, validation_data=test_data, callbacks=callbacks_list)\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x3Kp7kpuAx1w"
   },
   "source": [
    "## 4.2.8 Loading the Best Model\n",
    "\n",
    "Once you have finished training, run the following to automatically select the best performing model from the training folder and load it up again for evaluation.\n",
    "\n",
    "We also duplicate the model into another file name, and save its weights as well so that you can easily retrieve them.\n",
    "\n",
    "Optionally, you can also save the model (and model weights) into a fixed file name for easy retrieval later. The code to that can be found here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46031,
     "status": "ok",
     "timestamp": 1579696898666,
     "user": {
      "displayName": "Pat LEW",
      "photoUrl": "",
      "userId": "08279461782250315515"
     },
     "user_tz": -480
    },
    "id": "zRMYkXosFqg9",
    "outputId": "53201a32-750f-48bf-d1de-41a9a9ed6d6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model file:\n",
      "/content/drive/My Drive/Data/D4//segmentation_train_2020-01-22 12-12-44/seg_unet_resnet34_model.a.0035-acc-0.99-val_acc-0.94-0.63-loss-0.40.h5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# List all the .h5 files generated in your training folder.\n",
    "#\n",
    "list_of_files = glob.glob(training_session_folder + '/*')  \n",
    "list_of_files.sort()\n",
    "best_model_file = list_of_files[-1]\n",
    "\n",
    "print (\"Best model file:\")\n",
    "print (best_model_file)\n",
    "\n",
    "# Load up the best model\n",
    "#\n",
    "model = keras.models.load_model(best_model_file, \n",
    "                                custom_objects={\n",
    "                                    \"focal_loss_plus_jaccard_loss\": sm.losses.categorical_focal_jaccard_loss,\n",
    "                                    \"iou_score\": sm.metrics.iou_score})\n",
    "\n",
    "# TODO (Optional):\n",
    "# Save the model and the model weights into a separate file for easy retrieval.\n",
    "#\n",
    "#...#\n",
    "# And save it into another file.\n",
    "#\n",
    "model.save(training_session_folder + \"/a_segmentation_model.h5\")\n",
    " \n",
    "# Save the weights, too\n",
    "#\n",
    "model.save_weights(training_session_folder + \"/a_segmentation_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdVgb9VnCCTv"
   },
   "source": [
    "## 4.2.9 Evaluate Your Model Performance\n",
    "\n",
    "Run the following cells to display the training history, confusion matrix and the performance summary. If you are not satisfied with the performance, tune your parameters and retrain until you are satisfied.\n",
    "\n",
    "Once you are done, proceed to Part 3.\n",
    "\n",
    "*NOTE: We excluded the \"background\" label from the confusion matrix because there are significantly more background pixels.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x69E_N4aCPqC"
   },
   "outputs": [],
   "source": [
    "labels = [\"background\", \"top\", \"bottom\", \"one-piece\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 109204,
     "status": "ok",
     "timestamp": 1579697147741,
     "user": {
      "displayName": "Pat LEW",
      "photoUrl": "",
      "userId": "08279461782250315515"
     },
     "user_tz": -480
    },
    "id": "DrPpTkv1zSsK",
    "outputId": "0a536aed-7828-4751-bf65-88181bd7fdcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone-frozen training\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJUAAAEWCAYAAADfKKYPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEhERERERERGRIfv/Aavn2+kny5YuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 288, 192, 3)\n",
      "(550, 288, 192, 4)\n",
      "(550, 288, 192, 4)\n",
      "(30412800,)\n",
      "(30412800,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHoAAAGDCAYAAABUancDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkbChR5IkSZIkqZGwoUeSJEmSJKmR+H+JDXAs6f1sxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "--------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background       0.99      0.99      0.99  25694058\n",
      "         top       0.93      0.92      0.93   2378051\n",
      "      bottom       0.89      0.96      0.92   1446177\n",
      "   one-piece       0.87      0.89      0.88    894514\n",
      "\n",
      "    accuracy                           0.98  30412800\n",
      "   macro avg       0.92      0.94      0.93  30412800\n",
      "weighted avg       0.98      0.98      0.98  30412800\n",
      "\n",
      "\n",
      "Test Data:\n",
      "--------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background       0.99      0.98      0.98   9351285\n",
      "         top       0.82      0.78      0.80    928250\n",
      "      bottom       0.66      0.78      0.72    427116\n",
      "   one-piece       0.55      0.59      0.57    352549\n",
      "\n",
      "    accuracy                           0.94  11059200\n",
      "   macro avg       0.75      0.78      0.77  11059200\n",
      "weighted avg       0.95      0.94      0.95  11059200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This function is used to display the history the train/test accuracy/loss\n",
    "# of the Keras training.\n",
    "#\n",
    "#   history - Pass in the history returned from the model.fit(...) method.\n",
    "#\n",
    "def display_training_loss_and_accuracy(history):\n",
    "    \n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()    \n",
    "\n",
    "print (\"Backbone-frozen training\")\n",
    "display_training_loss_and_accuracy(history1)\n",
    "\n",
    "# print (\"Backbone-unfrozen training\")\n",
    "# display_training_loss_and_accuracy(history2)\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "def display_classification_confusion_matrix(keras_model, train_generator, test_generator, labels, mask=None):\n",
    "    \n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    actual_y_train = []\n",
    "    actual_y_test = []\n",
    "\n",
    "    train_generator.on_epoch_end()\n",
    "    train_generator.set_batch_size_to_1()\n",
    "    for i in range(0, train_generator.__len__()):\n",
    "        x, y = train_generator.__getitem__(i);\n",
    "\n",
    "        for n in range(0, x.shape[0]):\n",
    "            x_train.append(x[n])\n",
    "            y_train.append(y[n])\n",
    "            actual_y_train.append(keras_model.predict(x)[n])\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    actual_y_train = np.array(actual_y_train)\n",
    "\n",
    "    train_generator.on_epoch_end()\n",
    "\n",
    "    print (x_train.shape)\n",
    "    print (y_train.shape)\n",
    "    print (actual_y_train.shape)\n",
    "\n",
    "    test_generator.on_epoch_end()\n",
    "    test_generator.set_batch_size_to_1()\n",
    "    for i in range(0, test_generator.__len__()):\n",
    "        x, y = test_generator.__getitem__(i);\n",
    "\n",
    "        for n in range(0, x.shape[0]):\n",
    "            x_test.append(x[n])\n",
    "            y_test.append(y[n])\n",
    "            actual_y_test.append(keras_model.predict(x)[n])\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    actual_y_test = np.array(actual_y_test)\n",
    "\n",
    "    test_generator.on_epoch_end()\n",
    "\n",
    "    plt.figure(figsize=(20,6))  \n",
    "\n",
    "    labels = np.array(labels)\n",
    "    if mask is not None:\n",
    "        labels_masked = labels[mask]\n",
    "    else:\n",
    "        labels_masked = labels\n",
    "\n",
    "    # Convert the target labels into the categorical index\n",
    "    #\n",
    "    y_train_index = y_train.argmax(axis=len(y_train.shape)-1).flatten()\n",
    "    actual_y_train_index = actual_y_train.argmax(axis=len(y_train.shape)-1).flatten()\n",
    "    y_test_index = y_test.argmax(axis=len(y_train.shape)-1).flatten()\n",
    "    actual_y_test_index = actual_y_test.argmax(axis=len(y_train.shape)-1).flatten()\n",
    "\n",
    "    print (y_train_index.shape)\n",
    "    print (actual_y_train_index.shape)\n",
    "    \n",
    "    # Print the first Confusion Matrix for the training data\n",
    "    #\n",
    "    cm = confusion_matrix(y_train_index, actual_y_train_index)\n",
    "    if mask is not None:\n",
    "        cm = cm[:, mask][mask, :]\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, labels_masked, labels_masked)          \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Confusion Matrix (Train Data)')\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')        \n",
    "    \n",
    "    # Print the second Confusion Matrix for the test data\n",
    "    #    \n",
    "    cm = confusion_matrix(y_test_index, actual_y_test_index)\n",
    "    if mask is not None:\n",
    "        cm = cm[:, mask][mask, :]\n",
    "    \n",
    "    cm_df = pd.DataFrame(cm, labels_masked, labels_masked)          \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Confusion Matrix (Test Data)')\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')        \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Finally display the classification reports\n",
    "    #\n",
    "    print (\"Train Data:\")\n",
    "    print (\"--------------------------------------------------------\")\n",
    "    print(classification_report(actual_y_train_index, y_train_index, target_names=labels))\n",
    "    print (\"\")\n",
    "    print (\"Test Data:\")\n",
    "    print (\"--------------------------------------------------------\")\n",
    "    print(classification_report(actual_y_test_index, y_test_index, target_names=labels))\n",
    "    \n",
    "\n",
    "# Display the matrix, but exclude the background from the confusion matrix plot, \n",
    "# because there are significantly more background pixels than other pixels. \n",
    "#\n",
    "display_classification_confusion_matrix(model, train_data, test_data, labels, [False, True, True, True])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "practical-04b-colab-segmentation-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
